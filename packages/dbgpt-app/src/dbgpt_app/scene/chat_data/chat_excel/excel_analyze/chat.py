# ruff: noqa: E501
import json
import logging
import os
from pathlib import Path
from typing import Any, Dict, List, Type, Union

from dbgpt import SystemApp
from dbgpt.agent.util.api_call import ApiCall
from dbgpt.configs.model_config import DATA_DIR
from dbgpt.core import (
    ChatPromptTemplate,
    HumanPromptTemplate,
    MessagesPlaceholder,
    ModelMessage,
    ModelMessageRoleType,
    ModelOutput,
    ModelRequest,
    ModelRequestContext,
    SystemPromptTemplate,
)
from dbgpt.core.interface.file import _SCHEMA, FileStorageClient
from dbgpt.util.executor_utils import blocking_func_to_async
from dbgpt.util.json_utils import EnhancedJSONEncoder
from dbgpt.util.tracer import root_tracer, trace
from dbgpt_app.scene import BaseChat, ChatScene
from dbgpt_app.scene.base_chat import ChatParam
from dbgpt_app.scene.chat_data.chat_excel.config import ChatExcelConfig
from dbgpt_app.scene.chat_data.chat_excel.excel_analyze.language_detector import (
    detect_language,
)
from dbgpt_app.scene.chat_data.chat_excel.excel_learning.chat import ExcelLearning
from dbgpt_app.scene.chat_data.chat_excel.excel_reader import ExcelReader
from dbgpt_app.scene.chat_data.chat_excel.excel_schema_db import ExcelSchemaDao

logger = logging.getLogger(__name__)


class ChatExcel(BaseChat):
    """a Excel analyzer to analyze Excel Data"""

    chat_scene: str = ChatScene.ChatExcel.value()

    @classmethod
    def param_class(cls) -> Type[ChatExcelConfig]:
        return ChatExcelConfig

    def __init__(self, chat_param: ChatParam, system_app: SystemApp):
        """Chat Excel Module Initialization
        Args:
           - chat_param: Dict
            - chat_session_id: (str) chat session_id
            - current_user_input: (str) current user input
            - model_name:(str) llm model name
            - select_param:(str) file path
        """
        self.fs_client = FileStorageClient.get_instance(system_app)
        self.select_param = chat_param.select_param
        if not self.select_param:
            raise ValueError("Please upload the Excel document you want to talk toï¼")
        self.model_name = chat_param.model_name
        self.curr_config = chat_param.real_app_config(ChatExcelConfig)
        self.chat_param = chat_param
        self._bucket = "dbgpt_app_file"

        use_existing_db = False
        duckdb_path = None
        duckdb_table_name = None

        select_param_dict = self.select_param
        if isinstance(self.select_param, str):
            try:
                select_param_dict = json.loads(self.select_param)
            except json.JSONDecodeError as e:
                logger.error(f"è§£æselect_paramå¤±è´¥: {e}")
                select_param_dict = {}

        if isinstance(select_param_dict, dict):
            duckdb_path = select_param_dict.get("db_path")
            duckdb_table_name = select_param_dict.get("table_name")
            self._content_hash = select_param_dict.get("content_hash")

            if self._content_hash:
                try:
                    import sqlite3

                    current_file = Path(__file__)
                    project_root = current_file
                    for _ in range(9):
                        project_root = project_root.parent
                    meta_db_path = (
                        project_root
                        / "packages"
                        / "pilot"
                        / "data"
                        / "excel_cache"
                        / "excel_metadata.db"
                    )

                    if meta_db_path.exists():
                        conn = sqlite3.connect(str(meta_db_path))
                        cursor = conn.cursor()
                        cursor.execute(
                            "SELECT data_schema_json FROM excel_metadata WHERE content_hash = ?",
                            (self._content_hash,),
                        )
                        result = cursor.fetchone()
                        conn.close()

                        if result and result[0]:
                            select_param_dict["data_schema_json"] = result[0]
                            self.select_param = (
                                json.dumps(select_param_dict, ensure_ascii=False)
                                if isinstance(self.select_param, str)
                                else select_param_dict
                            )
                except Exception as e:
                    logger.warning(f"ä»æ•°æ®åº“é‡æ–°åŠ è½½ data_schema_json å¤±è´¥: {e}")

            if duckdb_path and os.path.exists(duckdb_path):
                use_existing_db = True
                logger.info(f"ä½¿ç”¨DuckDBç¼“å­˜: {duckdb_path}, è¡¨å: {duckdb_table_name}")
            elif duckdb_path:
                logger.warning(f"db_pathå­˜åœ¨ä½†æ–‡ä»¶ä¸å­˜åœ¨: {duckdb_path}")
        else:
            logger.warning("select_paramä¸æ˜¯å­—å…¸ç±»å‹ï¼Œä½¿ç”¨ä¼ ç»ŸExcelå¯¼å…¥")

        file_path, file_name, database_file_path, database_file_id = self._resolve_path(
            select_param_dict,
            chat_param.chat_session_id,
            self.fs_client,
            self._bucket,
            duckdb_path=duckdb_path,
        )

        use_cache_success = False
        if use_existing_db and duckdb_path:
            try:
                self.excel_reader = self._create_reader_from_duckdb(
                    chat_param.chat_session_id,
                    duckdb_path,
                    file_name,
                    duckdb_table_name,
                )
                # ä½¿ç”¨ excel_reader ä¸­å®é™…è·å–åˆ°çš„è¡¨åï¼ˆå¯èƒ½æ˜¯ä»æ•°æ®åº“æŸ¥è¯¢å¾—åˆ°çš„ï¼‰
                self._curr_table = self.excel_reader.table_name
                use_cache_success = True
                # ç¡®ä¿ database_file_path ä¸å®é™…ä½¿ç”¨çš„ duckdb_path ä¸€è‡´
                database_file_path = duckdb_path
                logger.info(f"æˆåŠŸä½¿ç”¨DuckDBç¼“å­˜ï¼Œè¡¨å: {self._curr_table}")
            except Exception as e:
                logger.warning(f"ä½¿ç”¨DuckDBç¼“å­˜å¤±è´¥ï¼Œå›é€€åˆ°é‡æ–°å¯¼å…¥: {e}")
                # åˆ é™¤æŸåçš„ç¼“å­˜æ–‡ä»¶
                try:
                    if os.path.exists(duckdb_path):
                        os.remove(duckdb_path)
                        logger.info(f"å·²åˆ é™¤æŸåçš„ç¼“å­˜æ–‡ä»¶: {duckdb_path}")
                except Exception as del_e:
                    logger.warning(f"åˆ é™¤ç¼“å­˜æ–‡ä»¶å¤±è´¥: {del_e}")
                use_cache_success = False

        if not use_cache_success:
            # å¦‚æœæœ‰ duckdb_path ä½†ç¼“å­˜åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨åŸæ¥çš„ duckdb_path
            actual_db_path = duckdb_path if duckdb_path else database_file_path
            
            # æ£€æŸ¥æ•°æ®åº“ä¸­æ˜¯å¦å·²æœ‰è¡¨ï¼ˆå¯èƒ½æ˜¯ excel_auto_register åˆ›å»ºçš„ï¼‰
            existing_table_name = None
            if actual_db_path and os.path.exists(actual_db_path):
                try:
                    import duckdb as duckdb_check
                    check_conn = duckdb_check.connect(database=actual_db_path, read_only=True)
                    query = (
                        "SELECT table_name FROM information_schema.tables "
                        "WHERE table_schema = 'main'"
                    )
                    tables_result = check_conn.execute(query).fetchall()
                    check_conn.close()
                    if tables_result:
                        existing_table_name = tables_result[0][0]
                        logger.info(f"å‘ç°å·²å­˜åœ¨çš„è¡¨: {existing_table_name}")
                except Exception as check_e:
                    logger.warning(f"æ£€æŸ¥å·²å­˜åœ¨è¡¨å¤±è´¥: {check_e}")
            
            if existing_table_name:
                # ä½¿ç”¨å·²å­˜åœ¨çš„è¡¨ï¼Œä¸éœ€è¦é‡æ–°å¯¼å…¥
                self._curr_table = existing_table_name
                self.excel_reader = self._create_reader_from_duckdb(
                    chat_param.chat_session_id,
                    actual_db_path,
                    file_name,
                    existing_table_name,
                )
                logger.info(f"ä½¿ç”¨å·²å­˜åœ¨çš„DuckDBè¡¨: {existing_table_name}")
            else:
                # æ²¡æœ‰å·²å­˜åœ¨çš„è¡¨ï¼Œéœ€è¦é‡æ–°åˆ›å»º
                self._curr_table = "data_analysis_table"
                self.excel_reader = ExcelReader(
                    chat_param.chat_session_id,
                    file_path,
                    file_name,
                    read_type="direct",
                    database_name=actual_db_path,
                    table_name=self._curr_table,
                    duckdb_extensions_dir=self.curr_config.duckdb_extensions_dir,
                    force_install=self.curr_config.force_install,
                )
            database_file_path = actual_db_path

        self._file_name = file_name
        self._database_file_path = database_file_path
        self._database_file_id = database_file_id
        self._query_rewrite_result = None
        self._last_sql_error = None
        self._current_suggested_questions = []

        self.api_call = ApiCall()
        super().__init__(chat_param=chat_param, system_app=system_app)

    def _create_reader_from_duckdb(
        self,
        conv_uid: str,
        duckdb_path: str,
        file_name: str,
        duckdb_table_name: str = None,
    ):
        import duckdb

        db_conn = duckdb.connect(database=duckdb_path, read_only=True)

        try:
            if not duckdb_table_name:
                query = (
                    "SELECT table_name FROM information_schema.tables "
                    "WHERE table_schema = 'main'"
                )
                tables_result = db_conn.execute(query).fetchall()
                if tables_result:
                    duckdb_table_name = tables_result[0][0]
                else:
                    raise ValueError(f"åœ¨DuckDBæ•°æ®åº“ä¸­æœªæ‰¾åˆ°ä»»ä½•è¡¨: {duckdb_path}")

            reader = object.__new__(ExcelReader)
            reader.conv_uid = conv_uid
            reader.db = db_conn
            reader.temp_table_name = duckdb_table_name
            reader.table_name = duckdb_table_name
            reader.excel_file_name = file_name

            return reader

        except Exception as e:
            logger.error(f"ä»DuckDBè¯»å–æ•°æ®å¤±è´¥: {e}")
            db_conn.close()
            raise

    def _resolve_path(
        self,
        file_param: Any,
        conv_uid: str,
        fs_client: FileStorageClient,
        bucket: str,
        duckdb_path: str = None,
    ) -> Union[str, str, str]:
        if isinstance(file_param, str) and os.path.isabs(file_param):
            file_path = file_param
            file_name = os.path.basename(file_param)
        else:
            if isinstance(file_param, dict):
                file_path = file_param.get("file_path", None)
                if not file_path:
                    raise ValueError("Not find file path!")
                else:
                    file_name = os.path.basename(file_path.replace(f"{conv_uid}_", ""))

            else:
                temp_obj = json.loads(file_param)
                file_path = temp_obj.get("file_path")
                if not file_path:
                    raise ValueError("Not find file path!")
                file_name = os.path.basename(file_path.replace(f"{conv_uid}_", ""))

        if duckdb_path and os.path.exists(duckdb_path):
            database_file_path = duckdb_path
            database_file_id = None
        else:
            database_root_path = os.path.join(DATA_DIR, "_chat_excel_tmp")
            os.makedirs(database_root_path, exist_ok=True)
            database_file_path = os.path.join(
                database_root_path, f"_chat_excel_{file_name}.duckdb"
            )
            database_file_id = None

        if file_path.startswith(_SCHEMA):
            file_path, file_meta = fs_client.download_file(file_path, dest_dir=DATA_DIR)
            file_name = os.path.basename(file_path)

            if not duckdb_path:
                database_file_path = os.path.join(
                    database_root_path, f"_chat_excel_{file_name}.duckdb"
                )
                database_file_id = f"{file_meta.file_id}_{conv_uid}"
                db_files = fs_client.list_files(
                    bucket,
                    filters={"file_id": database_file_id},
                )
                if db_files:
                    fs_client.download_file(db_files[0].uri, database_file_path)

        return file_path, file_name, database_file_path, database_file_id

    @trace()
    async def generate_input_values(self) -> Dict:
        if (
            hasattr(self, "_cached_input_values")
            and self._cached_input_values is not None
        ):
            return self._cached_input_values

        await self._ensure_data_analysis_table_exists()

        user_input = self.current_user_input.last_text
        detected_language = detect_language(user_input)
        self._detected_language = detected_language

        from dbgpt_app.scene.chat_data.chat_excel.excel_analyze.prompt import (
            get_prompt_templates_by_language,
        )

        prompt_templates = get_prompt_templates_by_language(detected_language)

        table_schema = await blocking_func_to_async(
            self._executor, self.excel_reader.get_create_table_sql, self._curr_table
        )
        colunms, datas = await blocking_func_to_async(
            self._executor, self.excel_reader.get_sample_data, self._curr_table
        )

        data_time_range = await blocking_func_to_async(
            self._executor, self._get_data_time_range, self._curr_table
        )

        query_rewrite_info = ""
        relevant_columns_info = ""

        select_param_dict = self.select_param
        if isinstance(self.select_param, str):
            try:
                select_param_dict = json.loads(self.select_param)
            except Exception as e:
                logger.warning(f"è§£æselect_param JSONå¤±è´¥: {e}")
                select_param_dict = None

        if select_param_dict and isinstance(select_param_dict, dict):
            data_schema_json = select_param_dict.get("data_schema_json")

            if data_schema_json:
                # ä½¿ç”¨stream_callä¸­å®Œæˆçš„æŸ¥è¯¢æ”¹å†™ç»“æœ
                rewrite_result = self._query_rewrite_result

                if rewrite_result and rewrite_result.get("rewritten_query"):
                    query_rewrite_info = f"""


ç”¨æˆ·çš„é—®é¢˜ï¼š{rewrite_result["rewritten_query"]}

ç›¸å…³å­—æ®µï¼š
{self._format_relevant_columns(rewrite_result.get("relevant_columns", []))}

åˆ†æå»ºè®®ï¼š
{self._format_analysis_suggestions(rewrite_result.get("analysis_suggestions", []))}

åˆ†æé€»è¾‘ï¼š
{rewrite_result.get("analysis_logic", "")}

æ¥ä¸‹æ¥è¯·æŒ‰ç…§æ ¼å¼è¦æ±‚ç”Ÿæˆsqlè¯­å¥è¿›è¡ŒæŸ¥è¯¢ã€‚
"""
                    extracted_knowledge = rewrite_result.get("_extracted_knowledge")
                    if extracted_knowledge:
                        await self._save_domain_knowledge(
                            extracted_knowledge, data_schema_json
                        )

                    try:
                        schema_obj = (
                            json.loads(data_schema_json)
                            if isinstance(data_schema_json, str)
                            else data_schema_json
                        )
                        all_columns = schema_obj.get("columns", [])

                        relevant_col_names = [
                            col.get("column_name", "")
                            for col in rewrite_result.get("relevant_columns", [])
                        ]

                        relevant_columns_details = []
                        for col_name in relevant_col_names:
                            for col_info in all_columns:
                                if col_info.get("column_name") == col_name:
                                    relevant_columns_details.append(col_info)
                                    break

                        if relevant_columns_details:
                            relevant_columns_info = (
                                self._format_relevant_columns_for_prompt(
                                    relevant_columns_details
                                )
                            )
                        else:
                            relevant_columns_info = "æœªæ‰¾åˆ°ç›¸å…³åˆ—çš„è¯¦ç»†ä¿¡æ¯ã€‚"

                    except Exception as col_err:
                        logger.warning(f"æå–åˆ—è¯¦ç»†ä¿¡æ¯å¤±è´¥: {col_err}")
                        relevant_columns_info = ""
                else:
                    # å¦‚æœæŸ¥è¯¢æ”¹å†™å¤±è´¥æˆ–æ²¡æœ‰ç»“æœï¼Œè®¾ç½®é»˜è®¤å€¼
                    query_rewrite_info = ""
                    relevant_columns_info = ""

        from dbgpt_app.scene.chat_data.chat_excel.excel_analyze.prompt import (
            _ANALYSIS_CONSTRAINTS_TEMPLATE,
        )

        analysis_constraints = _ANALYSIS_CONSTRAINTS_TEMPLATE.format(
            table_name=self._curr_table, display_type=self._generate_numbered_list()
        )

        input_values = {
            "user_input": self.current_user_input.last_text,
            "table_name": self._curr_table,
            "display_type": self._generate_numbered_list(),
            "table_schema": table_schema,
            "data_example": json.dumps(
                datas, cls=EnhancedJSONEncoder, ensure_ascii=False
            ),
            "query_rewrite_info": query_rewrite_info,
            "relevant_columns_info": relevant_columns_info,
            "data_time_range": data_time_range or "",
            "duckdb_syntax_rules": prompt_templates["duckdb_rules"],
            "analysis_constraints": analysis_constraints,
            "examples": prompt_templates["examples"],
        }

        self._cached_input_values = input_values
        return input_values

    async def _build_model_request(self) -> ModelRequest:
        detected_language = getattr(self, "_detected_language", "zh")

        from dbgpt_app.scene.chat_data.chat_excel.excel_analyze.prompt import (
            get_prompt_templates_by_language,
        )

        prompt_templates = get_prompt_templates_by_language(detected_language)

        dynamic_prompt = ChatPromptTemplate(
            messages=[
                SystemPromptTemplate.from_template(prompt_templates["system_prompt"]),
                MessagesPlaceholder(variable_name="chat_history"),
                HumanPromptTemplate.from_template(
                    prompt_templates["user_prompt_template"]
                ),
            ]
        )

        original_prompt = self.prompt_template.prompt
        self.prompt_template.prompt = dynamic_prompt

        try:
            return await super()._build_model_request()
        finally:
            self.prompt_template.prompt = original_prompt

    async def _save_domain_knowledge(self, knowledge: dict, current_schema_json: str):
        try:
            import sqlite3
            from datetime import datetime

            column_name = knowledge.get("column_name")
            knowledge_text = knowledge.get("knowledge")

            if not column_name or not knowledge_text:
                return

            schema_obj = (
                json.loads(current_schema_json)
                if isinstance(current_schema_json, str)
                else current_schema_json
            )
            columns = schema_obj.get("columns", [])

            knowledge_saved = False
            for col in columns:
                if col.get("column_name") == column_name:
                    existing_knowledge = col.get("domain_knowledge", "")
                    if knowledge_text in existing_knowledge:
                        return

                    col["domain_knowledge"] = (
                        f"{existing_knowledge}\nâ€¢ {knowledge_text}"
                        if existing_knowledge
                        else knowledge_text
                    )
                    knowledge_saved = True
                    break

            if not knowledge_saved:
                return

            current_file = Path(__file__)
            project_root = current_file
            for _ in range(9):
                project_root = project_root.parent
            meta_db_path = (
                project_root
                / "packages"
                / "pilot"
                / "data"
                / "excel_cache"
                / "excel_metadata.db"
            )

            if not meta_db_path.exists():
                return

            content_hash = getattr(self, "_content_hash", None)
            if not content_hash:
                return

            conn = sqlite3.connect(str(meta_db_path))
            cursor = conn.cursor()

            updated_schema_json = json.dumps(schema_obj, ensure_ascii=False, indent=2)

            cursor.execute(
                "UPDATE excel_metadata SET data_schema_json = ?, last_accessed = ? WHERE content_hash = ?",
                (updated_schema_json, datetime.now().isoformat(), content_hash),
            )

            conn.commit()
            conn.close()

            if hasattr(self, "select_param"):
                if isinstance(self.select_param, dict):
                    self.select_param["data_schema_json"] = updated_schema_json
                elif isinstance(self.select_param, str):
                    try:
                        param_dict = json.loads(self.select_param)
                        param_dict["data_schema_json"] = updated_schema_json
                        self.select_param = json.dumps(param_dict, ensure_ascii=False)
                    except Exception as e:
                        logger.warning(f"æ›´æ–° select_param å­—ç¬¦ä¸²å¤±è´¥: {e}")

        except Exception as e:
            logger.error(f"ä¿å­˜é¢†åŸŸçŸ¥è¯†å¤±è´¥: {e}", exc_info=True)

    def _clean_history_content(self, content: str) -> str:
        import re

        # å»é™¤ chart-view æ ‡ç­¾
        content = re.sub(
            r"<chart-view[^>]*>.*?</chart-view>", "", content, flags=re.DOTALL
        )
        
        # å»é™¤ SUGGESTED_QUESTIONS æ ‡è®°
        content = re.sub(
            r"<!--SUGGESTED_QUESTIONS:.*?-->", "", content, flags=re.DOTALL
        )
        
        # å»é™¤ vis-thinking æ ‡ç­¾ï¼ˆåŒ¹é…ä»»æ„æ•°é‡çš„åå¼•å·ï¼Œä»3ä¸ªåˆ°6ä¸ªï¼‰
        # åŒ¹é…æ ¼å¼ï¼š```vis-thinking ... ``` æˆ– ``````vis-thinking ... ``````
        content = re.sub(
            r"`{3,6}vis-thinking.*?`{3,6}", "", content, flags=re.DOTALL
        )
        
        # æ¸…ç†å¤šä½™çš„ç©ºè¡Œï¼ˆå°†3ä¸ªæˆ–æ›´å¤šè¿ç»­æ¢è¡Œç¬¦æ›¿æ¢ä¸º2ä¸ªï¼‰
        content = re.sub(r"\n{3,}", "\n\n", content)

        lines = content.split("\n")
        cleaned_lines = []
        skip_data = False

        for line in lines:
            if any(marker in line for marker in ["[{", '{"data":', '"rows":']):
                if len(line) > 200:
                    skip_data = True
                    continue

            if skip_data and ("}]" in line or line.strip() == "}"):
                skip_data = False
                continue

            if not skip_data:
                cleaned_lines.append(line)

        content = "\n".join(cleaned_lines)

        if len(content) > 1000:
            api_call_match = re.search(r"<api-call>.*?</api-call>", content, re.DOTALL)
            if api_call_match:
                before_api = content[: api_call_match.start()].strip()
                if len(before_api) > 200:
                    before_api = before_api[:200] + "..."
                content = before_api + "\n" + api_call_match.group(0)
            else:
                content = content[:1000] + "..."

        return content.strip()

    def _format_relevant_columns(self, columns: List[Dict]) -> str:
        """æ ¼å¼åŒ–ç›¸å…³åˆ—ä¿¡æ¯"""
        if not columns:
            return "æœªæŒ‡å®š"

        formatted = []
        for col in columns:
            col_name = col.get("column_name", "")
            usage = col.get("usage", "")
            formatted.append(f"  â€¢ {col_name}: {usage}")

        return "\n".join(formatted)

    def _format_analysis_suggestions(self, suggestions: List[str]) -> str:
        """æ ¼å¼åŒ–åˆ†æå»ºè®®"""
        if not suggestions:
            return "æ— "

        formatted = []
        for i, suggestion in enumerate(suggestions, 1):
            formatted.append(f"  {i}. {suggestion}")

        return "\n".join(formatted)

    def _format_relevant_columns_for_prompt(self, columns: List[Dict]) -> str:
        if not columns:
            detected_language = getattr(self, "_detected_language", "zh")
            is_english = detected_language == "en"
            return (
                "No relevant column information found."
                if is_english
                else "æœªæ‰¾åˆ°ç›¸å…³åˆ—ä¿¡æ¯ã€‚"
            )

        detected_language = getattr(self, "_detected_language", "zh")
        is_english = detected_language == "en"

        header = "Key fields to focus on:" if is_english else "ä½ åº”è¯¥é‡ç‚¹å…³æ³¨çš„å­—æ®µä¸ºï¼š"
        formatted_parts = [header]

        for col in columns:
            col_name = col.get("column_name", "")
            data_type = col.get("data_type", "")
            description = col.get("description", "")
            analysis_usage = col.get("analysis_usage", [])
            domain_knowledge = col.get("domain_knowledge", "")

            col_text = f"  â€¢ {col_name}"
            if data_type:
                label = "Data type" if is_english else "æ•°æ®ç±»å‹"
                col_text += f"\n    {label}: {data_type}"
            if description:
                label = "Description" if is_english else "æè¿°"
                col_text += f"\n    {label}: {description}"

            if domain_knowledge:
                label = "**Key Knowledge**" if is_english else "**å…³é”®çŸ¥è¯†**"
                col_text += f"\n    {label}: {domain_knowledge}"

            if analysis_usage:
                label = "Analysis usage" if is_english else "åˆ†æç”¨é€”"
                col_text += f"\n    {label}: {', '.join(analysis_usage)}"

            if "statistics_summary" in col:
                label = "Statistics" if is_english else "ç»Ÿè®¡ä¿¡æ¯"
                col_text += f"\n    {label}: {col['statistics_summary']}"

            if "unique_values_top20" in col:
                unique_vals = col["unique_values_top20"]
                label = "Possible values" if is_english else "å¯é€‰å€¼"
                label_partial = (
                    "Possible values (partial)" if is_english else "å¯é€‰å€¼(éƒ¨åˆ†)"
                )
                if len(unique_vals) <= 20:
                    col_text += f"\n    {label}: {', '.join(map(str, unique_vals))}"
                else:
                    partial_vals = ", ".join(map(str, unique_vals[:20]))
                    col_text += f"\n    {label_partial}: {partial_vals}..."

            formatted_parts.append(col_text)

        return "\n\n".join(formatted_parts)

    def _get_data_time_range(self, table_name: str) -> str:
        try:
            columns_result = self.excel_reader.db.sql(
                f"DESCRIBE {table_name}"
            ).fetchall()
            date_columns = []

            for col_info in columns_result:
                col_name = col_info[0]
                col_type = col_info[1].upper()
                if "DATE" in col_type or "TIME" in col_type:
                    date_columns.append(col_name)

            if not date_columns:
                return ""

            date_col = date_columns[0]
            query = (
                f'SELECT MIN("{date_col}") as min_date, '
                f'MAX("{date_col}") as max_date FROM "{table_name}"'
            )
            result = self.excel_reader.db.sql(query).fetchone()

            if result and result[0] and result[1]:
                min_date = result[0]
                max_date = result[1]

                if isinstance(min_date, str):
                    min_date = min_date[:10]
                else:
                    min_date = str(min_date)[:10]

                if isinstance(max_date, str):
                    max_date = max_date[:10]
                else:
                    max_date = str(max_date)[:10]

                time_range = f"\n\næ•°æ®æ—¶é—´èŒƒå›´ï¼š{min_date} è‡³ {max_date}"
                time_range += (
                    "\nï¼ˆæ³¨æ„ï¼šè¿›è¡ŒåŒæ¯”åˆ†ææ—¶ï¼Œè¯·ç¡®ä¿SQLæŸ¥è¯¢åŒ…å«è¶³å¤Ÿçš„å†å²æ•°æ®ï¼‰"
                )
                return time_range

        except Exception as e:
            logger.warning(f"è·å–æ•°æ®æ—¶é—´èŒƒå›´å¤±è´¥: {e}")

        return ""

    async def prepare(self):
        logger.info(f"{self.chat_mode} prepare start!")
        if self.has_history_messages():
            return None

        select_param_dict = self.select_param
        if isinstance(self.select_param, str):
            try:
                select_param_dict = json.loads(self.select_param)
            except Exception:
                select_param_dict = {}

        if select_param_dict and isinstance(select_param_dict, dict):
            summary_prompt = select_param_dict.get("summary_prompt")

            if summary_prompt and isinstance(summary_prompt, str):
                if self._curr_table != "data_analysis_table":
                    logger.info(f"ä½¿ç”¨DuckDBç¼“å­˜ï¼Œè¡¨ {self._curr_table} å·²å­˜åœ¨")
                else:
                    try:
                        await blocking_func_to_async(
                            self._executor, self._create_simple_data_analysis_table
                        )
                    except Exception as e:
                        logger.warning(f"ä½¿ç”¨ç¼“å­˜åˆ›å»ºè¡¨å¤±è´¥: {e}")

                await self._generate_and_save_excel_info(None)

                return ModelOutput(
                    error_code=0,
                    text="æ•°æ®åˆ†æç»“æ„å·²åŠ è½½ï¼ˆä½¿ç”¨ç¼“å­˜ï¼‰",
                    finish_reason="stop",
                )
        chat_param = ChatParam(
            chat_session_id=self.chat_session_id,
            current_user_input=f"[{self.excel_reader.excel_file_name}] Analyzeï¼",
            select_param=self.select_param,
            chat_mode=ChatScene.ExcelLearning,
            model_name=self.model_name,
            user_name=self.chat_param.user_name,
            sys_code=self.chat_param.sys_code,
        )
        if self._chat_param.temperature is not None:
            chat_param.temperature = self._chat_param.temperature
        if self._chat_param.max_new_tokens is not None:
            chat_param.max_new_tokens = self._chat_param.max_new_tokens

        learn_chat = ExcelLearning(
            chat_param,
            system_app=self.system_app,
            parent_mode=self.chat_mode,
            excel_reader=self.excel_reader,
        )
        result = await learn_chat.nostream_call()

        if (
            os.path.exists(self._database_file_path)
            and self._database_file_id is not None
        ):
            await blocking_func_to_async(self._executor, self.excel_reader.close)
            await blocking_func_to_async(
                self._executor,
                self.fs_client.upload_file,
                self._bucket,
                self._database_file_path,
                file_id=self._database_file_id,
            )

        await self._generate_and_save_excel_info(result)
        return result

    def _create_simple_data_analysis_table(self):
        try:
            tables = self.excel_reader.db.sql("SHOW TABLES").fetchall()
            table_names = [t[0] for t in tables]

            if self._curr_table in table_names:
                return

            if (
                hasattr(self.excel_reader, "table_name")
                and self.excel_reader.table_name
            ):
                source_table = self.excel_reader.table_name
                if source_table in table_names and source_table != self._curr_table:
                    sql = (
                        f"CREATE TABLE {self._curr_table} "
                        f"AS SELECT * FROM {source_table};"
                    )
                    self.excel_reader.db.sql(sql)
                    return

            if "temp_table" in table_names:
                sql = f"CREATE TABLE {self._curr_table} AS SELECT * FROM temp_table;"
                self.excel_reader.db.sql(sql)
                return

            table_name_attr = getattr(self.excel_reader, "table_name", None)
            logger.error(
                f"æ‰¾ä¸åˆ°æºè¡¨ï¼štemp_table ä¸å­˜åœ¨ï¼Œä¸” "
                f"excel_reader.table_name ({table_name_attr}) ä¹Ÿä¸å­˜åœ¨"
            )
            raise ValueError(f"æ‰¾ä¸åˆ°å¯ç”¨çš„æºè¡¨æ¥åˆ›å»º {self._curr_table}")
        except Exception as e:
            logger.error(f"Failed to create {self._curr_table}: {e}")
            raise

    async def _ensure_data_analysis_table_exists(self):
        try:
            tables = await blocking_func_to_async(
                self._executor,
                lambda: self.excel_reader.db.sql("SHOW TABLES").fetchall(),
            )
            table_names = [t[0] for t in tables]

            if self._curr_table not in table_names:
                await blocking_func_to_async(
                    self._executor, self._create_simple_data_analysis_table
                )
        except Exception as e:
            logger.error(f"ç¡®ä¿è¡¨å­˜åœ¨æ—¶å¤±è´¥: {e}")
            raise

    async def _generate_and_save_excel_info(self, learning_result: ModelOutput = None):
        try:
            columns, top_10_rows = await blocking_func_to_async(
                self._executor,
                self.excel_reader.get_sample_data,
                self._curr_table,
                10,
            )

            row_count, column_count = await blocking_func_to_async(
                self._executor, self._get_table_stats, self._curr_table
            )

            data_description = None
            data_schema_json = None

            if learning_result and learning_result.has_text:
                data_description = learning_result.text
            else:
                select_param_dict = self.select_param
                if isinstance(self.select_param, str):
                    try:
                        select_param_dict = json.loads(self.select_param)
                    except Exception:
                        select_param_dict = {}

                if isinstance(select_param_dict, dict):
                    data_description = select_param_dict.get("summary_prompt")
                    data_schema_json = select_param_dict.get("data_schema_json")

            suggested_questions = []
            if data_schema_json:
                try:
                    schema = json.loads(data_schema_json)
                    suggested_questions = schema.get("suggested_questions", [])
                except Exception as e:
                    logger.warning(f"ä» data_schema_json æå–æ¨èé—®é¢˜å¤±è´¥: {e}")

            schema_dao = ExcelSchemaDao()
            await blocking_func_to_async(
                self._executor,
                schema_dao.save_or_update,
                conv_uid=self.chat_session_id,
                file_name=self._file_name,
                table_name=self._curr_table,
                row_count=row_count,
                column_count=column_count,
                top_10_rows=top_10_rows,
                data_description=data_description,
                data_schema_json=data_schema_json,
                suggested_questions=suggested_questions,
                file_path=self._database_file_path,
                db_path=self._database_file_path,
                user_id=(
                    self.chat_param.user_id
                    if hasattr(self.chat_param, "user_id")
                    else None
                ),
                user_name=self.chat_param.user_name,
                sys_code=self.chat_param.sys_code,
            )
        except Exception as e:
            logger.error(f"ç”Ÿæˆå¹¶ä¿å­˜ Excel åŸºæœ¬ä¿¡æ¯å¤±è´¥: {e}")
            import traceback

            traceback.print_exc()

    def _get_table_stats(self, table_name: str) -> tuple:
        try:
            row_result = self.excel_reader.db.sql(
                f"SELECT COUNT(*) FROM {table_name}"
            ).fetchone()
            row_count = row_result[0] if row_result else 0

            columns, _ = self.excel_reader.get_columns(table_name)
            column_count = len(columns) if columns else 0

            return row_count, column_count
        except Exception as e:
            logger.error(f"è·å–è¡¨ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
            return 0, 0

    def stream_plugin_call(self, text):
        with root_tracer.start_span(
            "ChatExcel.stream_plugin_call.run_display_sql", metadata={"text": text}
        ):
            result = self.api_call.display_sql_llmvis(
                text,
                self.excel_reader.get_df_by_sql_ex,
            )
            logger.info(f"stream_plugin_call è¿”å›ç»“æœé•¿åº¦: {len(result) if result else 0}")
            logger.debug(f"stream_plugin_call è¿”å›å†…å®¹ï¼ˆå‰500å­—ç¬¦ï¼‰: {result[:500] if result else 'None'}")
            return result

    async def stream_call(self, text_output: bool = True, incremental: bool = False):
        # å…ˆè¿›è¡Œæµå¼æŸ¥è¯¢æ”¹å†™
        await self._ensure_data_analysis_table_exists()
        
        user_input = self.current_user_input.last_text
        detected_language = detect_language(user_input)
        self._detected_language = detected_language

        select_param_dict = self.select_param
        if isinstance(self.select_param, str):
            try:
                select_param_dict = json.loads(self.select_param)
            except Exception as e:
                logger.warning(f"è§£æselect_param JSONå¤±è´¥: {e}")
                select_param_dict = None

        # æ£€æŸ¥æ˜¯å¦éœ€è¦æŸ¥è¯¢æ”¹å†™
        need_rewrite = False
        data_schema_json = None
        table_schema = None
        chat_history = []
        
        if select_param_dict and isinstance(select_param_dict, dict):
            data_schema_json = select_param_dict.get("data_schema_json")
            if data_schema_json:
                need_rewrite = True
                # è·å–è¡¨ç»“æ„
                table_schema = await blocking_func_to_async(
                    self._executor, self.excel_reader.get_create_table_sql, self._curr_table
                )
                # æ„å»ºèŠå¤©å†å²
                if hasattr(self, "history_messages") and self.history_messages:
                    current_round_messages = []
                    last_role = None

                    for msg in self.history_messages:
                        if not hasattr(msg, "content"):
                            continue

                        role = getattr(msg, "role", "user")
                        content = msg.content

                        if hasattr(content, "get_text"):
                            try:
                                content = content.get_text()
                            except Exception:
                                content = str(content)
                        elif isinstance(content, list):
                            text_parts = []
                            for item in content:
                                if hasattr(item, "object") and hasattr(
                                    item.object, "data"
                                ):
                                    text_parts.append(str(item.object.data))
                                else:
                                    text_parts.append(str(item))
                            content = " ".join(text_parts)
                        else:
                            content = str(content)

                        content = self._clean_history_content(content)

                        if role == last_role and current_round_messages:
                            current_round_messages[-1]["content"] += "\n" + content
                        else:
                            current_round_messages.append(
                                {"role": role, "content": content}
                            )
                            last_role = role

                    chat_history = current_round_messages

        # å¦‚æœéœ€è¦æŸ¥è¯¢æ”¹å†™ï¼Œå…ˆè¿›è¡Œæµå¼æ”¹å†™
        if need_rewrite and self.llm_client:
            try:
                from dbgpt_app.scene.chat_data.chat_excel.query_rewrite import (
                    QueryRewriteAgent,
                )

                rewrite_agent = QueryRewriteAgent(self.llm_client, self.llm_model)
                
                # æµå¼è¾“å‡ºæŸ¥è¯¢æ”¹å†™ç»“æœ
                rewrite_result = None
                
                async for chunk in rewrite_agent.rewrite_query_stream(
                    self.current_user_input.last_text,
                    data_schema_json,
                    table_schema,
                    chat_history,
                ):
                    if isinstance(chunk, str):
                        # æµå¼è¾“å‡ºåŸå§‹æ–‡æœ¬ï¼ˆJSONæ ¼å¼ï¼‰
                        # è¾“å‡ºå®Œæ•´å†…å®¹ï¼Œè®©å‰ç«¯çœ‹åˆ°é€æ¸å¢é•¿çš„å®Œæ•´JSON
                        if text_output:
                            # ç›´æ¥è¾“å‡ºå®Œæ•´JSONæ–‡æœ¬ï¼Œå‰ç«¯ä¼šå®æ—¶æ˜¾ç¤ºå®Œæ•´å†…å®¹
                            yield chunk
                        else:
                            # ä½¿ç”¨ModelOutputæ ¼å¼ï¼Œè¾“å‡ºå®Œæ•´å†…å®¹
                            yield ModelOutput.build(
                                text=chunk,
                                error_code=0,
                                finish_reason="continue"
                            )
                    elif isinstance(chunk, dict):
                        # è§£æå®Œæˆï¼Œä¿å­˜ç»“æœ
                        rewrite_result = chunk
                        self._query_rewrite_result = rewrite_result
                        
                        # æ›´æ–°å¯¹è¯æ ‡é¢˜ï¼ˆconversation_titleï¼‰
                        conversation_title = rewrite_result.get("conversation_title")
                        logger.info(f"ğŸ“ rewrite_result ä¸­çš„ conversation_title: {conversation_title}")
                        if conversation_title:
                            try:
                                from dbgpt.storage.chat_history.chat_history_db import ChatHistoryDao
                                chat_history_dao = ChatHistoryDao()
                                updated_count = chat_history_dao.update_summary_by_uid(
                                    conversation_title, self.chat_param.chat_session_id
                                )
                                logger.info(f"âœ… æ›´æ–°å¯¹è¯æ ‡é¢˜: {conversation_title}, conv_uid: {self.chat_param.chat_session_id}, æ›´æ–°è¡Œæ•°: {updated_count}")
                            except Exception as title_e:
                                logger.warning(f"âŒ æ›´æ–°å¯¹è¯æ ‡é¢˜å¤±è´¥: {title_e}", exc_info=True)
                        else:
                            logger.info("âš ï¸ conversation_title ä¸ºç©ºï¼Œä¸æ›´æ–°å¯¹è¯æ ‡é¢˜")
                        
                        # æ£€æŸ¥é—®é¢˜æ˜¯å¦ä¸æ•°æ®è¡¨ç›¸å…³
                        is_relevant = rewrite_result.get("is_relevant", True)
                        if not is_relevant:
                            logger.info(f"æ£€æµ‹åˆ°éæ•°æ®åˆ†æé—®é¢˜ï¼Œè·¯ç”±åˆ°é€šç”¨å¯¹è¯: {self.current_user_input.last_text}")
                            # è·¯ç”±åˆ°é€šç”¨å¯¹è¯agent
                            async for response in self._handle_general_chat():
                                yield response
                            return
                        
                        # ä¿å­˜é¢†åŸŸçŸ¥è¯†
                        extracted_knowledge = rewrite_result.get("_extracted_knowledge")
                        if extracted_knowledge:
                            await self._save_domain_knowledge(
                                extracted_knowledge, data_schema_json
                            )
                        break
                
                # è¾“å‡ºå®Œæˆåï¼Œå±•ç¤ºæ ¼å¼åŒ–åçš„ç»“æœ
                if rewrite_result:
                    thinking_stage1 = self._format_query_rewrite_thinking(
                        rewrite_result
                    )
                    if thinking_stage1:
                        from dbgpt.vis.tags.vis_thinking import VisThinking

                        vis_thinking_output = VisThinking().sync_display(
                            content=thinking_stage1
                        )
                        if text_output:
                            yield vis_thinking_output
                        else:
                            yield ModelOutput.build(
                                text=vis_thinking_output, error_code=0, finish_reason="continue"
                            )
            except Exception as e:
                logger.warning(f"æµå¼Queryæ”¹å†™å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹é—®é¢˜: {e}")
                self._query_rewrite_result = None

        # ç”Ÿæˆè¾“å…¥å€¼ï¼ˆå¦‚æœå·²ç»å®ŒæˆæŸ¥è¯¢æ”¹å†™ï¼Œä¼šä½¿ç”¨ç¼“å­˜çš„ç»“æœï¼‰
        await self.generate_input_values()

        payload = await self._build_model_request()
        self._last_sql_error = None
        full_output = await self.call_llm_operator(payload)

        ai_response_text = ""
        view_message = ""
        
        if full_output:
            try:
                text_msg = full_output.text if full_output.has_text else ""
                view_msg = self.stream_plugin_call(text_msg)

                if self._last_sql_error:
                    logger.warning(f"SQLæ‰§è¡Œå¤±è´¥ï¼Œè·³è¿‡æ€»ç»“ç”Ÿæˆ: {self._last_sql_error[:100]}")
                    view_msg = full_output.gen_text_with_thinking(new_text=view_msg)
                    ai_full_response = self._combine_thinking_and_text(full_output, view_msg)
                    ai_response_text = ai_full_response
                    view_message = view_msg
                else:
                    # æ„å»ºå‰ç½®å†…å®¹ï¼ˆæ€è€ƒç»“æœ + å›¾è¡¨ï¼‰
                    import re
                    prefix_parts = []
                    
                    # 1. æ·»åŠ é—®é¢˜æ”¹å†™çš„æ€è€ƒç»“æœ
                    if self._query_rewrite_result:
                        thinking_stage1 = self._format_query_rewrite_thinking(
                            self._query_rewrite_result
                        )
                        if thinking_stage1:
                            from dbgpt.vis.tags.vis_thinking import VisThinking
                            vis_thinking_output = VisThinking().sync_display(
                                content=thinking_stage1
                            )
                            prefix_parts.append(vis_thinking_output)
                    
                    # 2. æå–å›¾è¡¨å†…å®¹
                    chart_pattern = r"(<chart-view.*?</chart-view>)"
                    chart_matches = re.findall(chart_pattern, view_msg, re.DOTALL)
                    if chart_matches:
                        all_chart_views = "\n\n".join(chart_matches)
                        prefix_parts.append(all_chart_views)
                    
                    # ç»„åˆå‰ç½®å†…å®¹
                    prefix_content = "\n\n".join(prefix_parts) if prefix_parts else ""
                    
                    # æµå¼è¾“å‡ºsummary
                    summary_result = None
                    async for chunk in self._generate_result_summary_stream(
                        text_msg, view_msg, text_output=text_output
                    ):
                        if isinstance(chunk, str):
                            # æµå¼è¾“å‡ºï¼šå‰ç½®å†…å®¹ + summaryæ–‡æœ¬
                            combined_output = f"{prefix_content}\n\n{chunk}" if prefix_content else chunk
                            if text_output:
                                yield combined_output
                            else:
                                yield ModelOutput.build(
                                    text=combined_output,
                                    error_code=0,
                                    finish_reason="continue"
                                )
                        elif isinstance(chunk, dict):
                            # æµå¼è¾“å‡ºå®Œæˆï¼Œè·å–æœ€ç»ˆç»“æœ
                            summary_result = chunk
                            break
                    
                    summary_text = summary_result.get("summary", "") if summary_result else ""
                    suggested_questions = summary_result.get("suggested_questions", []) if summary_result else []
                    
                    # ä¿å­˜æ¨èé—®é¢˜åˆ°å®ä¾‹å˜é‡ï¼Œä¾›å‰ç«¯è·å–
                    self._current_suggested_questions = suggested_questions
                    
                    # ç»„åˆæœ€ç»ˆè¾“å‡º
                    if summary_text:
                        if prefix_content:
                            view_message = f"{prefix_content}\n\n{summary_text}"
                        else:
                            view_message = summary_text
                    else:
                        # å³ä½¿æ€»ç»“ä¸ºç©ºï¼Œä¹Ÿæ˜¾ç¤ºæŸ¥è¯¢ç»“æœå’Œæç¤ºä¿¡æ¯
                        detected_language = getattr(self, "_detected_language", "zh")
                        is_english = detected_language == "en"
                        no_result_msg = "æŸ¥è¯¢å·²å®Œæˆï¼Œä½†æœªç”Ÿæˆæ€»ç»“ã€‚æŸ¥è¯¢ç»“æœå¦‚ä¸‹ï¼š" if not is_english else "Query completed, but no summary was generated. Query results:"
                        
                        if prefix_content:
                            view_message = f"{prefix_content}\n\n{no_result_msg}\n\n{view_msg}"
                        else:
                            view_message = f"{no_result_msg}\n\n{view_msg}"
                    
                    # å¦‚æœæœ‰æ¨èé—®é¢˜ï¼Œåœ¨view_msgæœ«å°¾æ·»åŠ ç‰¹æ®Šæ ‡è®°
                    if suggested_questions:
                        questions_json = json.dumps({"suggested_questions": suggested_questions}, ensure_ascii=False)
                        view_message += f"\n\n<!--SUGGESTED_QUESTIONS:{questions_json}-->"
                    
                    view_message = full_output.gen_text_with_thinking(new_text=view_message)
                    ai_response_text = self._combine_thinking_and_text(full_output, view_message)

                if text_output:
                    yield view_message
                else:
                    yield ModelOutput.build(
                        view_message,
                        "",
                        error_code=full_output.error_code if full_output else 0,
                        finish_reason=(
                            full_output.finish_reason if full_output else "stop"
                        ),
                    )
            except Exception as e:
                logger.error(f"å¤„ç†è¾“å‡ºæ—¶å‡ºé”™: {e}")
                error_msg = f"æ•°æ®æŸ¥è¯¢å¤±è´¥ï¼š{str(e)}"
                ai_response_text = error_msg
                view_message = error_msg
                if text_output:
                    yield error_msg
                else:
                    yield ModelOutput.build(
                        error_msg, "", error_code=1, finish_reason="error"
                    )
        else:
            error_msg = "ç”ŸæˆSQLå¤±è´¥ï¼Œè¯·é‡è¯•"
            ai_response_text = error_msg
            view_message = error_msg
            if text_output:
                yield error_msg
            else:
                yield ModelOutput.build(
                    error_msg, "", error_code=1, finish_reason="error"
                )
        
        # ä¿å­˜å¯¹è¯å†å²
        try:
            if ai_response_text:
                self.current_message.add_ai_message(ai_response_text)
            if view_message:
                self.current_message.add_view_message(view_message)
            await blocking_func_to_async(
                self._executor, self.current_message.end_current_round
            )
        except Exception as save_error:
            logger.error(f"ä¿å­˜å¯¹è¯å†å²å¤±è´¥: {save_error}", exc_info=True)

    async def _handle_final_output(
        self,
        final_output: ModelOutput,
        incremental: bool = False,
        check_error: bool = True,
    ):
        text_msg = final_output.text if final_output.has_text else ""
        view_msg = self.stream_plugin_call(text_msg)

        if check_error and self._last_sql_error:
            logger.warning(f"SQLæ‰§è¡Œå¤±è´¥ï¼Œè·³è¿‡æ€»ç»“ç”Ÿæˆ: {self._last_sql_error[:100]}")
            view_msg = final_output.gen_text_with_thinking(new_text=view_msg)
            ai_full_response = self._combine_thinking_and_text(final_output, view_msg)
            return ai_full_response, view_msg

        summary_result = await self._generate_result_summary(text_msg, view_msg)
        
        summary_text = summary_result.get("summary", "") if isinstance(summary_result, dict) else ""
        suggested_questions = summary_result.get("suggested_questions", []) if isinstance(summary_result, dict) else []
        
        # ä¿å­˜æ¨èé—®é¢˜åˆ°å®ä¾‹å˜é‡ï¼Œä¾›å‰ç«¯è·å–
        self._current_suggested_questions = suggested_questions

        if summary_text:
            import re

            chart_pattern = r"(<chart-view.*?</chart-view>)"
            chart_matches = re.findall(chart_pattern, view_msg, re.DOTALL)

            if chart_matches:
                all_chart_views = "\n\n".join(chart_matches)
                view_msg = f"{summary_text}\n\n{all_chart_views}"
            else:
                view_msg = f"{summary_text}\n\n{view_msg}"
            
            # å¦‚æœæœ‰æ¨èé—®é¢˜ï¼Œåœ¨view_msgæœ«å°¾æ·»åŠ ç‰¹æ®Šæ ‡è®°ï¼ˆå‰ç«¯å¯ä»¥è§£æï¼‰
            if suggested_questions:
                questions_json = json.dumps({"suggested_questions": suggested_questions}, ensure_ascii=False)
                view_msg += f"\n\n<!--SUGGESTED_QUESTIONS:{questions_json}-->"

        view_msg = final_output.gen_text_with_thinking(new_text=view_msg)
        ai_full_response = self._combine_thinking_and_text(final_output, view_msg)
        return ai_full_response, view_msg

    def _combine_thinking_and_text(
        self, final_output: ModelOutput, view_msg: str
    ) -> str:
        thinking_text = getattr(final_output, "thinking", None)

        if thinking_text:
            text_content = final_output.text if final_output.has_text else ""
            return f"{thinking_text}\n{text_content}".strip()
        else:
            return final_output.text if final_output.has_text else ""

    async def _handle_general_chat(self):
        """
        å¤„ç†é€šç”¨å¯¹è¯ï¼ˆéæ•°æ®åˆ†æé—®é¢˜ï¼‰
        ä½¿ç”¨LLMè¿›è¡Œç®€å•çš„å¯¹è¯å›å¤
        """
        try:
            detected_language = getattr(self, "_detected_language", "zh")
            is_english = detected_language == "en"
            
            if is_english:
                system_prompt = """You are a friendly AI assistant. The user is currently in a data analysis session but has asked a general question unrelated to data analysis. Please provide a brief, helpful response and gently remind them that you're here primarily to help with data analysis tasks."""
            else:
                system_prompt = """ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„AIåŠ©æ‰‹ã€‚ç”¨æˆ·å½“å‰å¤„äºæ•°æ®åˆ†æä¼šè¯ä¸­ï¼Œä½†æå‡ºäº†ä¸€ä¸ªä¸æ•°æ®åˆ†ææ— å…³çš„ä¸€èˆ¬æ€§é—®é¢˜ã€‚è¯·æä¾›ç®€çŸ­ã€æœ‰å¸®åŠ©çš„å›å¤ï¼Œå¹¶æ¸©å’Œåœ°æé†’ä»–ä»¬ä½ ä¸»è¦æ˜¯ç”¨æ¥å¸®åŠ©æ•°æ®åˆ†æä»»åŠ¡çš„ã€‚"""
            
            request = ModelRequest(
                model=self.llm_model,
                messages=[
                    ModelMessage(role=ModelMessageRoleType.SYSTEM, content=system_prompt),
                    ModelMessage(
                        role=ModelMessageRoleType.HUMAN,
                        content=self.current_user_input.last_text
                    )
                ],
                temperature=0.7,
                max_new_tokens=512,
                context=ModelRequestContext(stream=True),
            )
            
            if self.llm_client:
                import inspect
                
                stream_response = self.llm_client.generate_stream(request)
                full_text = ""
                
                if inspect.isasyncgen(stream_response):
                    async for chunk in stream_response:
                        try:
                            if hasattr(chunk, "has_text") and chunk.has_text:
                                chunk_text = chunk.text
                            elif hasattr(chunk, "text"):
                                try:
                                    chunk_text = chunk.text
                                except ValueError:
                                    continue
                            else:
                                continue
                            
                            if chunk_text:
                                full_text = chunk_text
                                yield chunk_text
                        except Exception as e:
                            logger.debug(f"è·å–chunk.textå¤±è´¥: {e}")
                            continue
                elif inspect.isgenerator(stream_response):
                    for chunk in stream_response:
                        try:
                            if hasattr(chunk, "has_text") and chunk.has_text:
                                chunk_text = chunk.text
                            elif hasattr(chunk, "text"):
                                try:
                                    chunk_text = chunk.text
                                except ValueError:
                                    continue
                            else:
                                continue
                            
                            if chunk_text:
                                full_text = chunk_text
                                yield chunk_text
                        except Exception as e:
                            logger.debug(f"è·å–chunk.textå¤±è´¥: {e}")
                            continue
                
                # ä¿å­˜å¯¹è¯å†å²
                if full_text:
                    self.current_message.add_ai_message(full_text)
                    self.current_message.add_view_message(full_text)
                    await blocking_func_to_async(
                        self._executor, self.current_message.end_current_round
                    )
            else:
                if is_english:
                    fallback_msg = "I'm here to help you with data analysis. If you have any questions about the data, feel free to ask!"
                else:
                    fallback_msg = "æˆ‘æ˜¯æ•°æ®åˆ†æåŠ©æ‰‹ï¼Œå¦‚æœæ‚¨æœ‰å…³äºæ•°æ®çš„é—®é¢˜ï¼Œéšæ—¶å¯ä»¥é—®æˆ‘ï¼"
                yield fallback_msg
                
        except Exception as e:
            logger.error(f"å¤„ç†é€šç”¨å¯¹è¯å¤±è´¥: {e}", exc_info=True)
            detected_language = getattr(self, "_detected_language", "zh")
            is_english = detected_language == "en"
            
            if is_english:
                error_msg = "I'm here to help with data analysis. Do you have any questions about the data?"
            else:
                error_msg = "æˆ‘ä¸»è¦è´Ÿè´£æ•°æ®åˆ†æï¼Œæ‚¨æœ‰ä»€ä¹ˆå…³äºæ•°æ®çš„é—®é¢˜å—ï¼Ÿ"
            yield error_msg
    
    def _format_query_rewrite_thinking(self, rewrite_result: dict) -> str:
        try:
            if not rewrite_result:
                return ""

            detected_language = getattr(self, "_detected_language", "zh")
            is_english = detected_language == "en"

            if is_english:
                title = "Question Understanding & Analysis\n\n"
                label_question = "1. Understood Question: "
                label_columns = "\n2. Relevant Fields:\n"
                label_suggestions = "\n3. Analysis Approach:\n"
                separator = ": "
            else:
                title = "é—®é¢˜ç†è§£ä¸åˆ†æ\n\n"
                label_question = "1.ç†è§£çš„é—®é¢˜ï¼š"
                label_columns = "\n2.éœ€è¦å…³æ³¨çš„å­—æ®µï¼š\n"
                label_suggestions = "\n3.åˆ†ææ€è·¯ï¼š\n"
                separator = "ï¼š"

            thinking_parts = [title]

            rewritten_query = rewrite_result.get("rewritten_query", "")
            if rewritten_query:
                thinking_parts.append(f"{label_question}{rewritten_query}\n")

            relevant_columns = rewrite_result.get("relevant_columns", [])
            if relevant_columns:
                thinking_parts.append(label_columns)
                for col in relevant_columns[:5]:
                    col_name = col.get("column_name", "")
                    usage = col.get("usage", "")
                    if col_name:
                        thinking_parts.append(f"  â€¢ {col_name}")
                        if usage:
                            thinking_parts.append(f"{separator}{usage}")
                        thinking_parts.append("\n")

            analysis_suggestions = rewrite_result.get("analysis_suggestions", [])
            if analysis_suggestions:
                thinking_parts.append(label_suggestions)
                for suggestion in analysis_suggestions[:5]:
                    thinking_parts.append(f"  â€¢ {suggestion}\n")

            return "".join(thinking_parts)

        except Exception as e:
            logger.warning(f"æ ¼å¼åŒ–Queryæ”¹å†™thinkingå¤±è´¥: {e}")
            return ""

    async def _generate_result_summary_stream(
        self, original_text: str, view_msg: str, text_output: bool = True
    ):
        """
        æµå¼ç”Ÿæˆç»“æœæ€»ç»“
        
        Yields:
            str: æµå¼è¾“å‡ºçš„summaryæ–‡æœ¬ï¼ˆåªè¾“å‡ºsummaryéƒ¨åˆ†ï¼Œä¸è¾“å‡ºsuggested_questionsï¼‰
            Dict: æœ€ç»ˆå®Œæ•´ç»“æœï¼ˆåŒ…å«summaryå’Œsuggested_questionsï¼‰
        """
        try:
            import html
            import json
            import re

            logger.info(f"å¼€å§‹ç”Ÿæˆç»“æœæ€»ç»“ï¼Œview_msgé•¿åº¦: {len(view_msg)}")
            logger.debug(f"view_msgå†…å®¹ï¼ˆå‰500å­—ç¬¦ï¼‰: {view_msg[:500]}")

            chart_pattern = r'<chart-view content="([^"]+)">'
            matches = re.findall(chart_pattern, view_msg)

            logger.info(f"æ‰¾åˆ°çš„chart-viewæ•°é‡: {len(matches)}")

            all_sql_results = []
            for match_str in matches:
                content_str = html.unescape(match_str)
                content_data = json.loads(content_str)

                sql = content_data.get("sql", "").strip()
                query_data = content_data.get("data", [])

                # å³ä½¿æŸ¥è¯¢ç»“æœä¸ºç©ºï¼Œä¹Ÿè®°å½•SQLå’Œç»“æœï¼ˆç©ºæ•°ç»„ï¼‰
                all_sql_results.append({"sql": sql, "result": query_data})

            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°chart-viewæ ‡ç­¾ï¼Œå°è¯•ä»åŸå§‹æ–‡æœ¬ä¸­æå–SQL
            if not all_sql_results:
                # å°è¯•ä»api-callæ ‡ç­¾ä¸­æå–SQL
                api_call_pattern = r'<api-call>.*?<sql>(.*?)</sql>.*?</api-call>'
                api_matches = re.findall(api_call_pattern, original_text, re.DOTALL)
                if api_matches:
                    for sql in api_matches:
                        sql = sql.strip()
                        if sql:
                            # å³ä½¿æ²¡æœ‰æŸ¥è¯¢ç»“æœï¼Œä¹Ÿè®°å½•SQLï¼ˆç»“æœä¸ºç©ºæ•°ç»„ï¼‰
                            all_sql_results.append({"sql": sql, "result": []})
                            logger.info(f"ä»api-callæ ‡ç­¾æå–åˆ°SQL: {sql[:100]}")

            # å³ä½¿æ²¡æœ‰SQLç»“æœï¼Œä¹Ÿç”Ÿæˆæ€»ç»“ï¼ˆè¯´æ˜æŸ¥è¯¢æ— ç»“æœï¼‰
            if not all_sql_results:
                logger.warning("æœªæ‰¾åˆ°chart-viewæ ‡ç­¾å’Œapi-callæ ‡ç­¾ï¼Œä½†ä»ç”Ÿæˆæ€»ç»“")
                # ç»§ç»­æ‰§è¡Œï¼Œç”Ÿæˆä¸€ä¸ªè¯´æ˜æŸ¥è¯¢æ— ç»“æœçš„æ€»ç»“

            history_context = ""
            if self.history_messages and len(self.history_messages) > 0:
                history_context = "\n=== å†å²å¯¹è¯ ===\n"
                for msg in self.history_messages[-6:]:
                    if not hasattr(msg, "content"):
                        continue

                    role = getattr(msg, "role", "user")
                    content = msg.content

                    if hasattr(content, "get_text"):
                        try:
                            content = content.get_text()
                        except Exception:
                            content = str(content)
                    elif isinstance(content, list):
                        text_parts = []
                        for item in content:
                            if hasattr(item, "object") and hasattr(item.object, "data"):
                                text_parts.append(str(item.object.data))
                            else:
                                text_parts.append(str(item))
                        content = " ".join(text_parts)
                    else:
                        content = str(content)

                    content = self._clean_history_content(content)

                    detected_language = getattr(self, "_detected_language", "zh")
                    is_english = detected_language == "en"
                    
                    # æ­£ç¡®è¯†åˆ«è§’è‰²
                    if role == "human":
                        role_display = "User" if is_english else "ç”¨æˆ·"
                    else:  # role == "ai" or "assistant" or "view"
                        role_display = "Assistant" if is_english else "åŠ©æ‰‹"
                    
                    history_context += f"{role_display}: {content}\n\n"

            detected_language = getattr(self, "_detected_language", "zh")
            is_english = detected_language == "en"

            sql_results_text = ""
            if all_sql_results:
                for i, sql_result in enumerate(all_sql_results, 1):
                    sql_label = f"Executed SQL {i}" if is_english else f"æ‰§è¡Œçš„SQL {i}"
                    result_label = f"Query Result {i}" if is_english else f"æŸ¥è¯¢ç»“æœ {i}"
                    sql_results_text += f"\n{sql_label}ï¼š\n{sql_result['sql']}\n\n"
                    result_json = json.dumps(
                        sql_result["result"], ensure_ascii=False, indent=2
                    )
                    sql_results_text += f"{result_label}ï¼š\n{result_json}\n"
                    
                    # å¦‚æœæŸ¥è¯¢ç»“æœä¸ºç©ºï¼Œæ·»åŠ è¯´æ˜
                    if not sql_result["result"]:
                        if is_english:
                            sql_results_text += "\n**Note**: The query returned no results (empty result set).\n"
                        else:
                            sql_results_text += "\n**æ³¨æ„**ï¼šæŸ¥è¯¢ç»“æœä¸ºç©ºï¼ˆæœªæ‰¾åˆ°åŒ¹é…çš„æ•°æ®ï¼‰ã€‚\n"
            else:
                # å¦‚æœæ²¡æœ‰SQLç»“æœï¼Œæ·»åŠ è¯´æ˜
                if is_english:
                    sql_results_text = "\n**Note**: No SQL query was executed or no query results were found.\n"
                else:
                    sql_results_text = "\n**æ³¨æ„**ï¼šæœªæ‰§è¡ŒSQLæŸ¥è¯¢æˆ–æœªæ‰¾åˆ°æŸ¥è¯¢ç»“æœã€‚\n"

            # è·å–æ•°æ®schemaä¿¡æ¯ï¼Œç”¨äºç”Ÿæˆæ¨èé—®é¢˜
            data_schema_info = ""
            select_param_dict = self.select_param
            if isinstance(self.select_param, str):
                try:
                    select_param_dict = json.loads(self.select_param)
                except Exception:
                    select_param_dict = {}
            
            if isinstance(select_param_dict, dict):
                data_schema_json = select_param_dict.get("data_schema_json")
                if data_schema_json:
                    try:
                        schema_obj = (
                            json.loads(data_schema_json)
                            if isinstance(data_schema_json, str)
                            else data_schema_json
                        )
                        table_description = schema_obj.get("table_description", "")
                        columns_summary = []
                        # åŒ…å«æ‰€æœ‰åˆ—ï¼Œä¸é™åˆ¶æ•°é‡
                        for col in schema_obj.get("columns", []):
                            col_name = col.get("column_name", "")
                            description = col.get("description", "")
                            
                            # æ„å»ºåˆ—ä¿¡æ¯æ–‡æœ¬
                            col_info_text = f"- {col_name}: {description}"
                            
                            # å¦‚æœæœ‰unique_values_top20ï¼Œè¡¥å……æ˜¾ç¤ºå‰5ä¸ªå€¼
                            if "unique_values_top20" in col:
                                unique_vals = col["unique_values_top20"]
                                if isinstance(unique_vals, list) and len(unique_vals) > 0:
                                    # å–å‰5ä¸ªå€¼
                                    top_5_values = unique_vals[:5]
                                    if is_english:
                                        col_info_text += f" (Example values: {', '.join(map(str, top_5_values))})"
                                    else:
                                        col_info_text += f" (ç¤ºä¾‹å€¼: {', '.join(map(str, top_5_values))})"
                            
                            columns_summary.append(col_info_text)
                        
                        # æ ¹æ®è¯­è¨€åˆ‡æ¢æ ‡ç­¾
                        if is_english:
                            data_schema_info = f"""
=== Data Table Information ===
Table Description: {table_description}
All Columns:
{chr(10).join(columns_summary)}
"""
                        else:
                            data_schema_info = f"""
=== æ•°æ®è¡¨ä¿¡æ¯ ===
è¡¨æè¿°: {table_description}
æ‰€æœ‰å­—æ®µ:
{chr(10).join(columns_summary)}
"""
                    except Exception as e:
                        logger.warning(f"è§£ædata_schema_jsonå¤±è´¥: {e}")

            if is_english:
                summary_prompt = f"""{history_context}
=== User's Current Question ===
{self.current_user_input.last_text}
{sql_results_text}
{data_schema_info}
**IMPORTANT - Language Requirement**:
- The user's question is in ENGLISH
- You MUST respond in ENGLISH
- Your answer MUST be in ENGLISH, not Chinese

**Task**:
Based on the conversation history, current question, SQL query results, and data schema information above, please generate:
1. An objective and accurate summary
2. 9 follow-up questions that would help users explore the data further based on the current analysis results

**Output Format**:
Please output a JSON object with the following structure:
```json
{{
  "summary": "Your objective summary based on SQL logic",
  "suggested_questions": [
    "Question 1 (simple question with standard answer)",
    "Question 2 (simple question with standard answer)",
    "Question 3 (simple question with standard answer)",
    "Question 4 (simple question with standard answer)",
    "Question 5 (simple question with standard answer)",
    "Question 6 (simple question with standard answer)",
    "Question 7 (open-ended question)",
    "Question 8 (open-ended question)",
    "Question 9 (open-ended question)"
  ]
}}
```

**Requirements for summary**:
- Explain the final query result
- **Constraints**:
  * Do NOT speculate, extrapolate, or provide subjective interpretations
- **Output Requirements**:
  * One sentence summary, no more than 100 words
  * Must be in ENGLISH

**Requirements for suggested_questions**:
- **First 6 questions**: Simple questions with clear standard answers 
- **Last 3 questions**: Medium difficulty questions that require some thinking and analysis
- **IMPORTANT**: All questions MUST be based on actual fields and data in the data table, DO NOT fabricate non-existent fields or data
- Questions should be based on the current analysis results and conversation context, you can think more broadly, but do not deviate from the topic
- All questions must be in ENGLISH

Please output the JSON directly, without any other text:"""  # noqa: E501
            else:
                summary_prompt = f"""{history_context}
=== ç”¨æˆ·å½“å‰é—®é¢˜ ===
{self.current_user_input.last_text}
{sql_results_text}
{data_schema_info}
**é‡è¦ - è¯­è¨€è¦æ±‚**ï¼š
- ç”¨æˆ·çš„é—®é¢˜æ˜¯**ä¸­æ–‡**
- ä½ å¿…é¡»ç”¨**ä¸­æ–‡**å›ç­”

**ä»»åŠ¡**ï¼š
æ ¹æ®ä¸Šè¿°å†å²å¯¹è¯ã€å½“å‰é—®é¢˜ã€SQLæŸ¥è¯¢ç»“æœå’Œæ•°æ®è¡¨ä¿¡æ¯ï¼Œè¯·ç”Ÿæˆï¼š
1. ä¸€æ®µå®¢è§‚ã€å‡†ç¡®çš„æ€»ç»“
2. 9ä¸ªåŸºäºå½“å‰åˆ†æç»“æœçš„æ¨èé—®é¢˜ï¼Œå¸®åŠ©ç”¨æˆ·è¿›ä¸€æ­¥æ¢ç´¢æ•°æ®

**è¾“å‡ºæ ¼å¼**ï¼š
è¯·è¾“å‡ºä¸€ä¸ªJSONå¯¹è±¡ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
```json
{{
  "summary": "åŸºäºSQLé€»è¾‘çš„å®¢è§‚æ€»ç»“",
  "suggested_questions": [
    "é—®é¢˜1ï¼ˆç®€å•é—®é¢˜ï¼Œæœ‰æ ‡å‡†ç­”æ¡ˆï¼‰",
    "é—®é¢˜2ï¼ˆç®€å•é—®é¢˜ï¼Œæœ‰æ ‡å‡†ç­”æ¡ˆï¼‰",
    "é—®é¢˜3ï¼ˆç®€å•é—®é¢˜ï¼Œæœ‰æ ‡å‡†ç­”æ¡ˆï¼‰",
    "é—®é¢˜4ï¼ˆç®€å•é—®é¢˜ï¼Œæœ‰æ ‡å‡†ç­”æ¡ˆï¼‰",
    "é—®é¢˜5ï¼ˆç®€å•é—®é¢˜ï¼Œæœ‰æ ‡å‡†ç­”æ¡ˆï¼‰",
    "é—®é¢˜6ï¼ˆç®€å•é—®é¢˜ï¼Œæœ‰æ ‡å‡†ç­”æ¡ˆï¼‰",
    "é—®é¢˜7ï¼ˆä¸­ç­‰éš¾åº¦é—®é¢˜ï¼‰",
    "é—®é¢˜8ï¼ˆä¸­ç­‰éš¾åº¦é—®é¢˜ï¼‰",
    "é—®é¢˜9ï¼ˆä¸­ç­‰éš¾åº¦é—®é¢˜ï¼‰"
  ]
}}
```

**æ€»ç»“çš„è¦æ±‚**ï¼š
- é˜è¿°æœ€ç»ˆæŸ¥è¯¢ç»“æœ
- **çº¦æŸæ¡ä»¶**ï¼š
  * ä¸è¦è¿›è¡Œæ¨æµ‹ã€å»¶ä¼¸æˆ–ä¸»è§‚è§£è¯»
- **è¾“å‡ºè¦æ±‚**ï¼š
  * ä¸€å¥è¯æ€»ç»“ï¼Œä¸è¶…è¿‡100å­—
  * å¿…é¡»ä½¿ç”¨**ä¸­æ–‡**

**æ¨èé—®é¢˜çš„è¦æ±‚**ï¼š
- **å‰6ä¸ªé—®é¢˜**ï¼šç®€å•çš„é—®é¢˜ï¼Œæœ‰æ˜ç¡®çš„æ ‡å‡†ç­”æ¡ˆ
- **å3ä¸ªé—®é¢˜**ï¼šä¸­ç­‰éš¾åº¦é—®é¢˜ï¼Œéœ€è¦ä¸€å®šçš„æ€è€ƒå’Œåˆ†æ
- **é‡è¦**ï¼šæ‰€æœ‰é—®é¢˜å¿…é¡»åŸºäºæ•°æ®è¡¨ä¸­çš„å®é™…å­—æ®µå’Œæ•°æ®ï¼Œå¯ä»¥å›´ç»•å…·ä½“çš„åˆ†ç±»å€¼è¿›è¡Œåˆ†æï¼Œä¸èƒ½å‡­ç©ºæé€ ä¸å­˜åœ¨çš„å­—æ®µæˆ–æ•°æ®
- é—®é¢˜åº”è¯¥åŸºäºå½“å‰åˆ†æç»“æœå’Œå¯¹è¯ä¸Šä¸‹æ–‡ï¼Œå¯ä»¥é€‚å½“å‘æ•£æ€ç»´ï¼Œä½†ä¸è¦åç¦»ä¸»é¢˜
- æ‰€æœ‰é—®é¢˜å¿…é¡»ä½¿ç”¨**ä¸­æ–‡**

è¯·ç›´æ¥è¾“å‡ºJSONï¼Œä¸è¦æœ‰å…¶ä»–æ–‡å­—ï¼š"""

            summary_request = ModelRequest(
                model=self.llm_model,
                messages=[
                    ModelMessage(
                        role=ModelMessageRoleType.HUMAN, content=summary_prompt
                    )
                ],
                temperature=0.3,
                max_new_tokens=2048,
                context=ModelRequestContext(stream=True),
            )

            if self.llm_client:
                import inspect
                
                # è·å–æµå¼å“åº”
                stream_response = self.llm_client.generate_stream(summary_request)
                
                full_text = ""
                previous_summary = ""
                
                if inspect.isasyncgen(stream_response):
                    async for chunk in stream_response:
                        chunk_text = ""
                        try:
                            if hasattr(chunk, "has_text") and chunk.has_text:
                                chunk_text = chunk.text
                            elif hasattr(chunk, "text"):
                                try:
                                    chunk_text = chunk.text
                                except ValueError:
                                    continue
                        except Exception as e:
                            logger.debug(f"è·å–chunk.textå¤±è´¥: {e}")
                            continue
                        
                        if chunk_text:
                            full_text = chunk_text
                            
                            # å°è¯•ä»æµå¼JSONä¸­æå–summaryéƒ¨åˆ†
                            try:
                                # æŸ¥æ‰¾ "summary" å­—æ®µçš„å¼€å§‹ä½ç½®
                                summary_start = full_text.find('"summary"')
                                if summary_start >= 0:
                                    # æ‰¾åˆ°summaryå­—æ®µå€¼å¼€å§‹çš„ä½ç½®ï¼ˆå†’å·åçš„å¼•å·ï¼‰
                                    value_start = full_text.find('"', summary_start + len('"summary"'))
                                    if value_start >= 0:
                                        value_start += 1  # è·³è¿‡å¼€å§‹å¼•å·
                                        # æŸ¥æ‰¾summaryå€¼çš„ç»“æŸä½ç½®ï¼ˆè€ƒè™‘è½¬ä¹‰å­—ç¬¦ï¼‰
                                        value_end = value_start
                                        while value_end < len(full_text):
                                            if full_text[value_end] == '"' and full_text[value_end - 1] != '\\':
                                                break
                                            value_end += 1
                                        
                                        if value_end > value_start:
                                            current_summary = full_text[value_start:value_end]
                                            # è¾“å‡ºå®Œæ•´çš„summaryå†…å®¹ï¼ˆé€æ¸å¢é•¿ï¼‰
                                            if len(current_summary) > len(previous_summary):
                                                previous_summary = current_summary
                                                
                                                if text_output:
                                                    yield current_summary
                                                else:
                                                    yield ModelOutput.build(
                                                        text=current_summary,
                                                        error_code=0,
                                                        finish_reason="continue"
                                                    )
                            except Exception as parse_err:
                                # å¦‚æœè§£æå¤±è´¥ï¼Œç»§ç»­ç­‰å¾…æ›´å¤šå†…å®¹
                                logger.debug(f"è§£æsummaryæµå¼è¾“å‡ºå¤±è´¥: {parse_err}")
                                continue
                elif inspect.isgenerator(stream_response):
                    for chunk in stream_response:
                        chunk_text = ""
                        try:
                            if hasattr(chunk, "has_text") and chunk.has_text:
                                chunk_text = chunk.text
                            elif hasattr(chunk, "text"):
                                try:
                                    chunk_text = chunk.text
                                except ValueError:
                                    continue
                        except Exception as e:
                            logger.debug(f"è·å–chunk.textå¤±è´¥: {e}")
                            continue
                        
                        if chunk_text:
                            full_text = chunk_text
                            
                            # å°è¯•ä»æµå¼JSONä¸­æå–summaryéƒ¨åˆ†
                            try:
                                summary_start = full_text.find('"summary"')
                                if summary_start >= 0:
                                    value_start = full_text.find('"', summary_start + len('"summary"'))
                                    if value_start >= 0:
                                        value_start += 1
                                        value_end = value_start
                                        while value_end < len(full_text):
                                            if full_text[value_end] == '"' and full_text[value_end - 1] != '\\':
                                                break
                                            value_end += 1
                                        
                                        if value_end > value_start:
                                            current_summary = full_text[value_start:value_end]
                                            # è¾“å‡ºå®Œæ•´çš„summaryå†…å®¹ï¼ˆé€æ¸å¢é•¿ï¼‰
                                            if len(current_summary) > len(previous_summary):
                                                previous_summary = current_summary
                                                
                                                if text_output:
                                                    yield current_summary
                                                else:
                                                    yield ModelOutput.build(
                                                        text=current_summary,
                                                        error_code=0,
                                                        finish_reason="continue"
                                                    )
                            except Exception as parse_err:
                                logger.debug(f"è§£æsummaryæµå¼è¾“å‡ºå¤±è´¥: {parse_err}")
                                continue
                
                # æµå¼è¾“å‡ºå®Œæˆåï¼Œè§£æå®Œæ•´JSONå¹¶è¿”å›ç»“æœ
                if full_text:
                    try:
                        # æå–JSONéƒ¨åˆ†
                        json_str = full_text
                        if "```json" in json_str.lower():
                            start_idx = json_str.lower().find("```json")
                            if start_idx >= 0:
                                content_start = json_str.find("\n", start_idx) + 1
                                if content_start > 0:
                                    end_idx = json_str.find("```", content_start)
                                    if end_idx > content_start:
                                        json_str = json_str[content_start:end_idx].strip()
                        
                        if "```" in json_str and "```json" not in json_str.lower():
                            start_idx = json_str.find("```")
                            content_start = json_str.find("\n", start_idx) + 1
                            if content_start > 0:
                                end_idx = json_str.find("```", content_start)
                                if end_idx > content_start:
                                    json_str = json_str[content_start:end_idx].strip()
                        
                        # å°è¯•æå–JSONå¯¹è±¡
                        if "{" in json_str and "}" in json_str:
                            start = json_str.find("{")
                            end = json_str.rfind("}") + 1
                            if start >= 0 and end > start:
                                json_str = json_str[start:end]
                        
                        result = json.loads(json_str)
                        summary_text = result.get("summary", "")
                        suggested_questions = result.get("suggested_questions", [])
                        
                        if not summary_text:
                            summary_text = full_text
                        
                        yield {
                            "summary": summary_text,
                            "suggested_questions": suggested_questions[:9] if isinstance(suggested_questions, list) else [],
                        }
                        return
                    except json.JSONDecodeError as e:
                        logger.warning(f"è§£ææ€»ç»“JSONå¤±è´¥: {e}ï¼Œä½¿ç”¨åŸå§‹æ–‡æœ¬")
                        yield {
                            "summary": full_text,
                            "suggested_questions": [],
                        }
                        return
            else:
                logger.warning("llm_clientæœªåˆå§‹åŒ–ï¼Œæ— æ³•ç”Ÿæˆæ€»ç»“")

            yield {"summary": "", "suggested_questions": []}

        except Exception as e:
            logger.warning(f"ç”Ÿæˆç»“æœæ€»ç»“å¤±è´¥: {e}", exc_info=True)
            yield {"summary": "", "suggested_questions": []}
